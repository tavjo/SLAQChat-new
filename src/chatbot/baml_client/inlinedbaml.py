###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> MyClient {\n  provider \"openai\"\n  options {\n    api_key env.OPENAI_API_KEY\n    model \"gpt-4o\"\n    temperature 0.1\n  }\n}\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    mutliplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "data_summarizer.baml": "class DataSummarizer {\n    Next_worker string @description(\"The next worker to call : 'responder'\")\n    summary string @description(\"The summary of the input message\")\n    user_query string @description(\"The user's query\")\n}\n\nfunction SummarizeData(inputMessage: string, user_query: string) -> DataSummarizer {\n    client MyClient\n    prompt #\"\n    Summarize the input message in a concise manner. Ensure the summary remains relevant to the user's query. If the input message is already concise, return it as the summary.\n    {{inputMessage}}\n    {{user_query}}\n    {{ctx.output_format}}\n    \"#\n}\n\ntest summary {\n    functions [SummarizeData]\n    args {\n        inputMessage #\"\n            The protocol for the sample NHP-220630FLY-2 can be accessed [here](https://nextseek.mit.edu/seek/sop/uid=P.FLY-220823-V1_P---NHP_housing.docx/).\n        \"#\n        user_query #\"\n            What is the protocol for the sample NHP-220630FLY-2?\n        \"#\n    }\n}\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.74.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "responder.baml": "// Defining a data model.\nclass Responder {\n    Next_worker string @description(\"The next worker to call\")\n    aggregatedMessages string @description(\"Same as inputMessage\")\n    user_query string @description(\"The original user query\")\n    // prev_worker string @description(\"The previous worker that was used\")\n}\n\n// Create a function to respond to the user's query.\nfunction Respond(inputMessage: string, workers: map<string, string>, user_query: string, prev_worker: string) -> Responder {\n    client MyClient\n      prompt #\"\n        Sequentially use the workers in the order of {{ workers }} to respond to the user's query. \n        If the worker has 'optional' in the name, only use it as needed.\n        Never return the same worker name multiple times.\n        Return the next worker as the worker's name (i.e. 'validator') as provided in the workers map.\n        Once you have a response from the \"validator\", the next worker must be \"FINISH\".\n        {{inputMessage}}\n        {{user_query}}\n        {{prev_worker}}\n        {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample input. Open the VSCode playground to run this.\ntest myresponse {\n    functions [Respond]\n    args {\n        inputMessage #\"\n            The protocol for the sample NHP-220630FLY-15 can be accessed [here](https://nextseek.mit.edu/seek/sop/uid=P.FLY-220823-V1_P---NHP_housing.docx/).\n        \"#\n        workers #\"\n            \"data_summarizer\" \"1.(optional) Summarize the data if response is longer than 100 words\"\n            \"response_formatter\" \"2.(optional)Format the response if data_summarizer is used\"\n            \"validator\" \"3.Validate the response\"\n            \"FINISH\" \"4.Finish the conversation\"\n        \"#\n        user_query #\"What is the protocol for the sample NHP-220630FLY-15?\"#\n    }\n}\n",
    "response_formatter.baml": "class ResponseFormatter {\n    Next_worker string @description(\"The next worker to call : responder\")\n    formattedResponse string @description(\"The formatted response to the user\")\n    name string @description(\"The name of the current worker : response_formatter\")\n}\n\nfunction FormatResponse(user_query: string, inputMessage: string) -> ResponseFormatter {\n\n    client MyClient\n        prompt #\"\n\n        Format the {{inputMessage}} as a polished response to the user. \n        To polish the inputMessage, remove extra whitespace, name of the worker, and the next worker.\n        If original user query is included in the inputMessage string, remove it.\n        In the final formatted response, include: \n        1) The summary but remove 'Summary:'.\n        2) The metadata in json format but remove fields with empty strings.\n\n        {{inputMessage}}\n        {{user_query}}\n        {{ctx.output_format}}\n        \"#\n}\n\ntest myresponse {\n\n    functions [FormatResponse]\n    args {\n        inputMessage #\"\n            Can you tell more more about PAV-220630FLY-1031? Summary: The sample with UID \"PAV-220630FLY-1031\" is named \"29518-190327\" and is associated with the scientist JoAnne Flynn. It is categorized as a \"Scan\" type sample and is linked to the protocol \"P.FLY-231011-V1_Patient-Visit-CD8.docx\". The sample was created on March 27, 2019, and is part of the Flynn Lab. Additional notes mention \"P0099\". The sample is a child of \"NHP-220630FLY-2\". More details can be found at the provided URI.\n\n            Metadata:\n            ```json\n            {\n                \"UID\": \"PAV-220630FLY-1031\",\n                \"Name\": \"29518-190327\",\n                \"Scientist\": \"JoAnne Flynn\",\n                \"RecordDate\": \"\",\n                \"Protocol\": \"P.FLY-231011-V1_Patient-Visit-CD8.docx\",\n                \"Type\": \"Scan\",\n                \"Procedure\": \"\",\n                \"CollectionTime\": \"\",\n                \"Parent\": \"NHP-220630FLY-2\",\n                \"VisitFacility\": \"Flynn Lab\",\n                \"VisitLocation\": \"\",\n                \"Notes\": \"P0099\",\n                \"Publish_uri\": \"https://fairdomhub.org/samples/23142\",\n                \"TestType\": \"\",\n                \"TestResult\": \"\",\n                \"TestResultFile\": \"\",\n                \"Coscientist\": \"\",\n                \"ProcedureDuration\": \"\",\n                \"DurationUnits\": \"\",\n                \"SampleCreationDate\": \"2019-03-27 00:00:00\",\n                \"BALInstilledVolume\": \"\",\n                \"BALCollectedVolume\": \"\",\n                \"VolumeUnits\": \"\",\n                \"Treatment1\": \"\",\n                \"Treatment1Type\": \"\",\n                \"Treatment1Route\": \"\",\n                \"Treatment1Dose\": \"\",\n                \"Treatment1DoseUnits\": \"\",\n                \"Treatment2\": \"\",\n                \"Treatment2Type\": \"\",\n                \"Treatment2Route\": \"\",\n                \"Treatment2Dose\": \"\",\n                \"Treatment2DoseUnits\": \"\",\n                \"Treatment3\": \"\",\n                \"Treatment3Type\": \"\",\n                \"Treatment3Route\": \"\",\n                \"Treatment3Dose\": \"\",\n                \"Treatment3DoseUnits\": \"\",\n                \"Treatment4\": \"\",\n                \"Treatment4Type\": \"\",\n                \"Treatment4Route\": \"\",\n                \"Treatment4Dose\": \"\",\n                \"Treatment4DoseUnits\": \"\",\n                \"Treatment5\": \"\",\n                \"Treatment5Type\": \"\",\n                \"Treatment5Route\": \"\",\n                \"Treatment5Dose\": \"\",\n                \"Treatment5DoseUnits\": \"\",\n                \"TestType2\": \"\",\n                \"TestResult2\": \"\",\n                \"TestResultFile2\": \"\",\n                \"TestType3\": \"\",\n                \"TestResult3\": \"\",\n                \"TestResultFile3\": \"\",\n                \"Protocol_Classification\": \"\",\n                \"Classification\": \"\",\n                \"ExperimentalTimepoint\": \"\",\n                \"Treatment1Parent\": \"\",\n                \"Treatment2Parent\": \"\",\n                \"Treatment3Parent\": \"\",\n                \"Treatment4Parent\": \"\",\n                \"Treatment5Parent\": \"\",\n                \"NumInjections\": \"\"\n            }\n            ```.\n        \"#\n    }\n}\n\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "supervisor.baml": "\n// Define Supervisor class\nclass Supervisor {\n    Next_worker string @description(\"The next worker to call\")\n    aggregatedMessages string @description(\"The aggregated responses from all workers used\")\n    user_query string @description(\"The user's query\")\n}\n\nfunction Supervise(Messages: string, workers: map<string, string>) -> Supervisor {\n    client MyClient\n    prompt #\"\n        You are a supervisor that decides which worker to call next based on the user's query.\n        Decide which worker from the list of workers to call next based on the user's query and/or the messages from the previous worker and the worker's description.\n        **Only call the necessary workers to answer the user's query.**\n        Return the next worker, the aggregated messages, and the user's query.\n        If no worker has been called yet, return the user's query for aggregatedMessages.\n        Once you have enough information to answer the user's query, return the next worker as \"responder\".\n        {{ Messages }}\n        {{ workers }}\n        {{ ctx.output_format }}\n\n    \"#\n}\ntest mysupervisor {\n    functions [Supervise]\n    args {\n        Messages #\"\n            What is the protocol for the sample NHP-220630FLY-15?\n        \"#\n        workers {\n            \"descendant_metadata_retriever\" \"Retrieve descendant metadata for the sample\"\n            \"link_retriever\" \"Retrieve link for the sample and/or the associatedprotocol\"\n            \"basic_sample_info_retriever\" \"Retrieve basic sample info for the sample\"\n            \"responder\" \"Validate and respond to the user's query\"\n        }\n    }\n}",
    "validator.baml": "// Defining a data model.\nclass Validator {\n    Valid bool @description(\"Whether the response is valid\")\n    Clarifying_Question string @description(\"A clarifying question to the user if Valid is false\")\n    originalMessage string @description(\"The message from the responder\")\n    Next_worker string @description(\"The next worker to call : 'responder'\")\n    name string @description(\"The name of the current worker : 'validator'\")\n}\n\n// Create a function to validate the response from the responder.\nfunction ValidateResponse(user_query: string, response: string) -> Validator {\n  client MyClient\n  prompt #\"\n    Validate the relevance of the response to the user's query. \n    The next worker should always be the 'responder' unless otherwise specified in the response. Return the original message (response) as a string.\n    {{ user_query }}\n    {{ response }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample response. Open the VSCode playground to run this.\ntest myresponse {\n    functions [ValidateResponse]\n    args {\n        response #\"\n            The protocol for the sample NHP-220630FLY-15 can be accessed [here](https://nextseek.mit.edu/seek/sop/uid=P.FLY-220823-V1_P---NHP_housing.docx/).\n        \"#\n        user_query #\"What is the protocol for the sample NHP-220630FLY-15?\"#\n    }\n}",
}

def get_baml_files():
    return file_map