###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    mutliplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.74.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
    "validator.baml": "// Defining a data model.\nclass Validator {\n    Valid bool\n    Clarifying_Question string\n    Metadata string\n    Next_worker string\n}\n\n// Create a function to validate the response from the responder.\nfunction ValidateResponse(response: string) -> Validator {\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Validate the response from the responder. The next worker should always be the 'responder' unless otherwise specified in the response. Return the metadata in the response as a string.\n    {{ response }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample response. Open the VSCode playground to run this.\ntest myresponse {\n    functions [ValidateResponse]\n    args {\n        response #\"\n            [HumanMessage(content='Can you tell me a little about this sample: NHP-220630FLY-15?', additional_kwargs={}, response_metadata={}, id='fd2f06da-48fd-4049-91c2-89a3ca43d387'), HumanMessage(content='Summary: The sample \"NHP-220630FLY-15\" is a male Macaca fascicularis, originating from China and housed at the Flynn Lab. The sample is part of the \"IgG\" cohort and is involved in the \"CD8 Depletion\" study, funded by NIH R56AI139053, which investigates the role of CD8 T cells in controlling tuberculosis. The sample has a total Colony Forming Unit (CFU) count of 2,392,635, with specific counts in the lung and lymph nodes. The total pathology score is 41, with lung and lymph node scores of 15 and 22, respectively. The study design includes specific depletion and necropsy dates, and the protocol used is documented in \"P.FLY-220823-V1_P---NHP_housing.docx\".\\n\\nMetadata: \\n```json\\n{\\n    \"UID\": \"NHP-220630FLY-15\",\\n    \"Name\": \"29918\",\\n    \"DateOfBirth\": \"2013-08-08 00:00:00\",\\n    \"Sex\": \"M\",\\n    \"Species\": \"Macaca fascicularis\",\\n    \"Origin\": \"China\",\\n    \"Facility\": \"Flynn Lab\",\\n    \"Notes\": \"JF/PL19-40A\",\\n    \"Scientist\": \"JoAnne Flynn\",\\n    \"Publish_uri\": \"https://fairdomhub.org/samples/19993\",\\n    \"Cohort\": \"IgG\",\\n    \"Study\": \"CD8 Depletion\",\\n    \"Funder\": \"NIH R56AI139053 Contribution of CD8 T cells in controlling tuberculosis (MPI Flynn/Lin)\",\\n    \"TotalCFU\": \"2392635\",\\n    \"LungCFU\": \"1169675\",\\n    \"LymphNodeCFU\": \"1222960\",\\n    \"TotalPathologyScore\": \"41\",\\n    \"LungPathologyScore\": \"15\",\\n    \"LymphNodePathologyScore\": \"22\",\\n    \"CFUUnits\": \"Colony Forming Unit Counts\",\\n    \"StudyDesign\": \"Depletion: 2019-03-06 00:00:00; LibP: 2019-03-21 00:00:00; Nx: 2019-05-06 00:00:00\",\\n    \"Link_StudyDesign\": \"http://fairdata.mit.edu:8080/seek/datafile/uid=D.FILE-240216FLY-2_CD8-Depletion.jpg/\",\\n    \"Protocol\": \"P.FLY-220823-V1_P---NHP_housing.docx\"\\n}\\n```', additional_kwargs={}, response_metadata={}, name='basic_sample_info_retriever', id='1a7ca988-96df-4114-9722-0c402f7d18d5')]\n        \"#\n    }\n}",
}

def get_baml_files():
    return file_map